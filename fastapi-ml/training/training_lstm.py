# âœ… í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
import joblib  # ëª¨ë¸ ì €ì¥ìš©
import sys
import os

# ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from preprocessing.preprocessing_lstm import preprocess_lstm, preprocess_lstm_by_region  # ì „ì²˜ë¦¬ í•¨ìˆ˜ ì„í¬íŠ¸

# LSTM ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_lstm(df, sequence_length=12, epochs=50, batch_size=32):
    """
    LSTM ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    #  ì „ì²˜ë¦¬ ìˆ˜í–‰ (ì‹œí€€ìŠ¤ ìƒì„± ë° ì •ê·œí™” í¬í•¨)
    X_seq, y_seq, scaler_X, scaler_y = preprocess_lstm(df, sequence_length)

    # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
    X_train, X_val, y_train, y_val = train_test_split(
        X_seq, y_seq, test_size=0.2, shuffle=False  # ì‹œê³„ì—´ì´ë¯€ë¡œ ì…”í”Œ X
    )

    # LSTM ëª¨ë¸ êµ¬ì„±
    model = Sequential()
    model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(0.2))  # ê³¼ì í•© ë°©ì§€ìš© Dropout
    model.add(Dense(1))  # ì¶œë ¥ì¸µ (ì˜ˆì¸¡ê°’ 1ê°œ)

    # ì»´íŒŒì¼
    model.compile(optimizer='adam', loss='mse')

    # í•™ìŠµ (EarlyStopping í¬í•¨)
    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[early_stop],
        verbose=1
    )

    # ğŸ”¹ ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    model.save('models/models_lstm.h5')  # ëª¨ë¸ ì €ì¥
    joblib.dump(scaler_X, 'models/lstm_scaler_X.pkl')
    joblib.dump(scaler_y, 'models/lstm_scaler_y.pkl')

    print("LSTM ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")

    return model

# ì§€ì—­ë³„ ëª¨ë¸ìƒì„±
def train_lstm_by_region(df, sequence_length=12):
    region_data = preprocess_lstm_by_region(df, sequence_length)

    for region, data in region_data.items():
        X_seq = data['X_seq']
        y_seq = data['y_seq']
        scaler_X = data['scaler_X']
        scaler_y = data['scaler_y']

        if len(X_seq) == 0:
            print(f"[Skip] {region} - ë°ì´í„° ë¶€ì¡±")
            continue

        # ëª¨ë¸ ì •ì˜
        model = Sequential([
            LSTM(64, input_shape=X_seq.shape[1:]),
            Dense(1)
        ])
        model.compile(optimizer='adam', loss='mse')

        # í•™ìŠµ
        model.fit(X_seq, y_seq, epochs=30, batch_size=16, verbose=1)

        # ì €ì¥ ê²½ë¡œ
        os.makedirs('models/region', exist_ok=True)
        model.save(f'models/region/{region}_lstm.h5')
        joblib.dump(scaler_X, f'models/region/{region}_scaler_X.pkl')
        joblib.dump(scaler_y, f'models/region/{region}_scaler_y.pkl')

        print(f"{region} í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
