import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
# ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from preprocessing.preprocessing_xgboost import preprocess_xgboost

def training_xgboost(df):
    """
    XGBoost ë°ì´í„° í•™ìŠµ
    """
    X_xgb, Y_xgb, le, df = preprocess_xgboost(df)
    X_train_xgb, X_test_xgb, Y_train_xgb, Y_test_xgb = train_test_split(X_xgb, Y_xgb, test_size=0.2, random_state=42)

    # XGBoost ë¶„ë¥˜ê¸° ëª¨ë¸ ê°ì²´
    xgb_model = xgb.XGBRegressor(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=5,
            random_state=42
        )

    xgb_model.fit(X_train_xgb, Y_train_xgb)
    xgb_pred = xgb_model.predict(X_test_xgb)

    # ëª¨ë¸ í‰ê°€
    xgb_mse = mean_squared_error(Y_test_xgb, xgb_pred)
    xgb_rmse = np.sqrt(xgb_mse)
    xgb_r2 = r2_score(Y_test_xgb, xgb_pred)

    # ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    xgb_results = {"XGBoost":{ 
            'model': xgb_model,
            'le': le,
            'mse': xgb_mse,
            'rmse': xgb_rmse,
            'r2': xgb_r2,
            'X_test': X_test_xgb,
            'y_test': Y_test_xgb,
            'df': df}
        }
    
    os.makedirs('models', exist_ok=True)
    joblib.dump(xgb_model, 'models/model_xgboost.pkl')
    joblib.dump(le, f'models/xgboost_label_encoder.pkl') # ğŸ”¹ LabelEncoder ì €ì¥
